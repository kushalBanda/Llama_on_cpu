{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "from langchain.llms import CTransformers\n",
    "from src.helper import *\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "# instruction = \"Convert the following text from English to Hindi: \\n\\n {text}\"\n",
    "instruction = \"Give a proper summary of the book?\"\n",
    "\n",
    "CUSTOM_SYSTEM_PROMPT=\"You are an advanced assistant that provides summary of the book: \\n\\n {text}\"\n",
    "\n",
    "SYSTEM_PROMPT = B_SYS + CUSTOM_SYSTEM_PROMPT + E_SYS\n",
    "template = B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "\n",
    "prompt = PromptTemplate(template = template, input_variables = ['text'])\n",
    "\n",
    "llm = CTransformers(model = '/Users/kushalbanda/Generative AI/Courses/ineuron/LLMs on CPU/model/llama-2-7b-chat.ggmlv3.q4_0.bin',\n",
    "                model_type = 'llama',\n",
    "                config = {'max_new_tokens': 128,\n",
    "                        'temperature': 0.8}\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_Chain = LLMChain(llm = llm, prompt = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Certainly! \"Harry Potter\" is a popular children's book series written by J.K. Rowling. The story follows the adventures of a young wizard named Harry Potter and his friends Ron Weasley and Hermione Granger as they attend Hogwarts School of Witchcraft and Wizardry.\n",
      "\n",
      "The books are set in a world where magic is real, and follow Harry's journey from being an awkward and unpopular boy to becoming a confident and powerful wizard. Along the way, he must confront the dark wizard Lord Voldemort, who\n"
     ]
    }
   ],
   "source": [
    "print(LLM_Chain.run(\"Harry Potter\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushalbanda/miniconda3/envs/Image_Captioning/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import CTransformers\n",
    "from src.helper import *\n",
    "\n",
    "# Load the PDF File\n",
    "loader = DirectoryLoader('data/',\n",
    "                        glob = \"*.pdf\",\n",
    "                        loader_cls = PyPDFLoader)\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "# Split Text into Chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50)\n",
    "\n",
    "text_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                model_kwargs = {'device': 'cpu'})\n",
    "\n",
    "# Convert the Text Chunks into Embeddings and Create a FAISS vector Store\n",
    "vector_store = FAISS.from_documents(text_chunks, embeddings)\n",
    "\n",
    "llm = CTransformers(model = '/Users/kushalbanda/Generative AI/Courses/ineuron/LLMs on CPU/model/llama-2-7b-chat.ggmlv3.q4_0.bin',\n",
    "                    model_type = 'llama',\n",
    "                    config = {'max_new_tokens': 128,\n",
    "                            'temperature': 0.01})\n",
    "\n",
    "qa_prompt = PromptTemplate(template=template, input_variables=['context', 'question'])\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm = llm,\n",
    "                                    chain_type = 'stuff',\n",
    "                                    retriever = vector_store.as_retriever(search_kwargs = {'k': 2}),\n",
    "                                    return_source_documents = False,\n",
    "                                    chain_type_kwargs = {'prompt': qa_prompt})\n",
    "\n",
    "user_input = \"Tell me about Rainfall Measurement of the paper\"\n",
    "\n",
    "result = chain({'query': user_input})\n",
    "print(f\"Answer: {result['result']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Image_Captioning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
